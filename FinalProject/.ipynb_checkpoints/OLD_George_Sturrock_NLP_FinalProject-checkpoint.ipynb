{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling IMDB Movie Reviews\n",
    "### DS 7337 - Natural Laguage Processing - FInal Project\n",
    "#### George C. Sturrock\n",
    "##### April 14, 2019\n",
    "##### Resources\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/\n",
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-10-10.0.14393-SP0\n",
      "Python: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Requests: 2.21.0\n",
      "BeatifulSoup: 4.7.1\n",
      "json: 2.0.9\n",
      "Numpy Version: 1.16.2\n",
      "Pandas Version: 0.24.2\n",
      "Pattern Version: 3.6\n",
      "pyLDAvis Versoin: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "import platform; print(\"Platform:\", platform.platform())\n",
    "import os\n",
    "import sys; print(\"Python:\", sys.version)\n",
    "import requests; print(\"Requests:\", requests.__version__)\n",
    "from urllib import request; (\"urllib:\", request.__version__)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import sleep\n",
    "\n",
    "#Web Scraping\n",
    "import bs4; print(\"BeatifulSoup:\", bs4.__version__)\n",
    "from bs4 import BeautifulSoup\n",
    "import json; print(\"json:\", json.__version__)\n",
    "\n",
    "#Python Basics\n",
    "import numpy as np; print(\"Numpy Version:\", np.__version__)\n",
    "import pandas as pd; print(\"Pandas Version:\", pd.__version__)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns;\n",
    "import string\n",
    "\n",
    "#scikit learn\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import stop_words\n",
    "#print(stop_words.ENGLISH_STOP_WORDS)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pattern; print(\"Pattern Version:\", pattern.__version__)\n",
    "from pattern.en import tag, parse, Sentence, parsetree, suggest, lemma, wordnet\n",
    "from pattern.vector import Document, Model, TFIDF, TF, words, stem, PORTER, LEMMA\n",
    "\n",
    "#pyLDAvis\n",
    "import pyLDAvis; print(\"pyLDAvis Versoin:\", pyLDAvis.__version__)\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "The first three films in the \"Rocky\" series will be utilized to collect reviews for noun phrase chunking.  Link to the main user review page for each of the three movies are shown below.  To assure both positive and negative reviews are collected, there are two links per movie.  One is sorted descending by user rating.  The other is sorted ascending by user rating.  Both links have \"spoiler alert\" messages suppressed as these reviews are often more akin to a summarization of the movie plot instead of a true review.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rocky movie list.  Two links for each movie to assure positive and negative reviews are captured.  \n",
    "#Sort descending by Review Rating.  Sort ascending by Review Rating.\n",
    "\n",
    "#Rocky\n",
    "rockyDict = {\"aRocky\":\"https://www.imdb.com/title/tt0075148/reviews?spoiler=hide&sort=userRating&dir=asc&ratingFilter=0\", \n",
    "         \"dRocky\":\"https://www.imdb.com/title/tt0075148/reviews?spoiler=hide&sort=userRating&dir=desc&ratingFilter=0\", \n",
    "#Rocky 2\n",
    "         \"dRocky 2\":\"https://www.imdb.com/title/tt0079817/reviews?spoiler=hide&sort=userRating&dir=desc&ratingFilter=0\",\n",
    "         \"aRocky 2\":\"https://www.imdb.com/title/tt0079817/reviews?spoiler=hide&sort=userRating&dir=asc&ratingFilter=0\",\n",
    "#Rocky 3\n",
    "         \"dRocky 3\":\"https://www.imdb.com/title/tt0084602/reviews?spoiler=hide&sort=userRating&dir=desc&ratingFilter=0\",\n",
    "         \"aRocky 3\":\"https://www.imdb.com/title/tt0084602/reviews?spoiler=hide&sort=userRating&dir=asc&ratingFilter=0\"\n",
    "            }\n",
    "\n",
    "rockyKeys = rockyDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping IMDB Movie Review Titles\n",
    "The individual links to the user reviews are collected below.  A get request uses each of the links in the \"rockyDict\" python dictionary.  The response is parsed by Beautiful Soup to find the individual links to each individual review.  The review URLs along with the movie name are written to a dataframe named dfRockyReviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewUrls = list()\n",
    "dfRockyReviews = pd.DataFrame(columns = ['Movie', 'ReviewURL'])\n",
    "\n",
    "for r in rockyKeys:\n",
    "    #print(r, rockyDict[r])\n",
    "    response = requests.get(rockyDict[r])\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    rUrls = [\"http:\" + s.attrs['href'] for s in soup.find_all(href = True, class_ = 'title')]\n",
    "    reviewUrls = reviewUrls + rUrls\n",
    "    for u in rUrls:\n",
    "        dfRockyReviews = dfRockyReviews.append({'Movie':r[1:], 'ReviewURL':u}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the dfRockyReviews dataframe is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>ReviewURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149538/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw4247059/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149534/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw2406266/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw3451942/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie                ReviewURL\n",
       "0  Rocky  http:/review/rw0149538/\n",
       "1  Rocky  http:/review/rw4247059/\n",
       "2  Rocky  http:/review/rw0149534/\n",
       "3  Rocky  http:/review/rw2406266/\n",
       "4  Rocky  http:/review/rw3451942/"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRockyReviews[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping IMDB Movie Review Details\n",
    "The individual review URLs collected above will be requested and parsed to retrieve key qualitative and categorical data about each review along with the review text itself.  These details are stored in a new dataframe named dfReviewDetails.  The first five records are this dataframe are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>ReviewUrl</th>\n",
       "      <th>ReviewDate</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149538/</td>\n",
       "      <td>1999-11-25</td>\n",
       "      <td>Dumbest, Most Cornball Film Ever Made</td>\n",
       "      <td>I still remember my initial outrage that this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw4247059/</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>Rubbish</td>\n",
       "      <td>The fight scenes are pathetic and the acting i...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149534/</td>\n",
       "      <td>1998-08-19</td>\n",
       "      <td>overrated piece of cheese</td>\n",
       "      <td>grubby late-night fare achieved way too much s...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw2406266/</td>\n",
       "      <td>2011-03-30</td>\n",
       "      <td>I can't believe the script was made into a mov...</td>\n",
       "      <td>I was told by many that Rocky is a beautiful m...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw3451942/</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>Hate me if you want but I didn't like this film</td>\n",
       "      <td>I'm going to come out and say it. I didn't lik...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie                ReviewUrl  ReviewDate  \\\n",
       "0  Rocky  http:/review/rw0149538/  1999-11-25   \n",
       "1  Rocky  http:/review/rw4247059/  2018-07-21   \n",
       "2  Rocky  http:/review/rw0149534/  1998-08-19   \n",
       "3  Rocky  http:/review/rw2406266/  2011-03-30   \n",
       "4  Rocky  http:/review/rw3451942/  2016-04-15   \n",
       "\n",
       "                                         ReviewTitle  \\\n",
       "0              Dumbest, Most Cornball Film Ever Made   \n",
       "1                                            Rubbish   \n",
       "2                          overrated piece of cheese   \n",
       "3  I can't believe the script was made into a mov...   \n",
       "4    Hate me if you want but I didn't like this film   \n",
       "\n",
       "                                              Review Rating Language  \n",
       "0  I still remember my initial outrage that this ...      1  English  \n",
       "1  The fight scenes are pathetic and the acting i...      1  English  \n",
       "2  grubby late-night fare achieved way too much s...      2  English  \n",
       "3  I was told by many that Rocky is a beautiful m...      3  English  \n",
       "4  I'm going to come out and say it. I didn't lik...      3  English  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReviewDetails = pd.DataFrame(columns=['Movie', 'ReviewUrl', 'ReviewDate', 'ReviewTitle', 'Review', 'Rating', \n",
    "                                        'Language'])\n",
    "counter = 0\n",
    "\n",
    "for r in reviewUrls:\n",
    "    fullUrl = \"https://www.imdb.com\" + r[5:]\n",
    "    response2 = requests.get(fullUrl)\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "    rjson = soup2.find('script', type = 'application/ld+json').text\n",
    "    rjson = json.loads(rjson)\n",
    "    \n",
    "    try:\n",
    "        rating = rjson['reviewRating']['ratingValue']\n",
    "    except Exception as e:\n",
    "        #print(\"No User Rating\")\n",
    "        rating = 5\n",
    "        \n",
    "    ### Add stemming logic to review body\n",
    "    \n",
    "    dfReviewDetails = dfReviewDetails.append({'Movie':dfRockyReviews.Movie[counter], 'ReviewUrl':r, \n",
    "                                              'ReviewDate':rjson['dateCreated'], 'ReviewTitle':rjson['name'], \n",
    "                                              'Review':rjson['reviewBody'], 'Rating':rating, \n",
    "                                              'Language':rjson['inLanguage']}, ignore_index=True)\n",
    "    counter += 1\n",
    "\n",
    "dfReviewDetails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot below shows movie review ratings for the reviews collected in the prior step. The original \"Rocky\" is widely considered the best of the \"Rocky\" series.  It won multiple Oscars and introduced \"Steady-Cam\" technology to the movie world.  However, the sample of user reviews collected tell a different story.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16d9c1284e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotdf = dfReviewDetails.sort_values(by=['ReviewDate'])\n",
    "plotdf.Rating = plotdf.Rating.astype('int64')\n",
    "plotdf.ReviewDate = pd.to_datetime(plotdf.ReviewDate)\n",
    "plotdf = plotdf.groupby(['Movie']).mean().reset_index()\n",
    "sns.barplot(x='Movie', y='Rating', data=plotdf.sort_values(by=['Rating'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering\n",
    "#### Create Additional Features for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nerList = []\n",
    "hypernymList = []\n",
    "lemmaList = []\n",
    "\n",
    "sw = stop_words.ENGLISH_STOP_WORDS\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#tx = tag(dfReviewDetails.Review[2], tokenize=True)\n",
    "\n",
    "#Create Lemmatize, NER, Hypernyms version of each review for topic modeling\n",
    "for dfr in dfReviewDetails.Review:\n",
    "    tlist = []\n",
    "    poslist = []\n",
    "    nlist = []\n",
    "    hlist = []\n",
    "    t1 = tag(dfr, tokenize=True)\n",
    "    for t, pos in t1:\n",
    "        if t not in sw and t not in string.punctuation:\n",
    "            if pos != \"NNPS\" and pos != \"NNP\":\n",
    "                tlist.append(lemma(t))\n",
    "                poslist.append(pos)\n",
    "            else:\n",
    "                nlist.append(t)\n",
    "                tlist.append(t)\n",
    "                poslist.append(pos)\n",
    "            if pos.startswith(\"N\") or pos.startswith(\"V\"):\n",
    "                s = wordnet.synsets(t, pos = pos)\n",
    "                try:\n",
    "                    sout = str(s[0].hypernyms(recursive=False, depth=None))[9:]\n",
    "                    sout = sout.split('.')[0]\n",
    "                    hlist.append(sout)\n",
    "                except Exception as e:\n",
    "                    #print(t2, p2, e) \n",
    "                    pass\n",
    "                \n",
    "    lt = \" \".join(l for l in tlist)\n",
    "    nl = \" \".join(n for n in nlist)\n",
    "    hl = \" \".join(h for h in hlist)\n",
    "    lemmaList.append(lt)\n",
    "    nerList.append(nl)\n",
    "    hypernymList.append(hl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReviewDetails['nerReview'] = nerList\n",
    "dfReviewDetails['lemmaReview'] = lemmaList\n",
    "dfReviewDetails['hyperReview'] = hypernymList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>ReviewUrl</th>\n",
       "      <th>ReviewDate</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Language</th>\n",
       "      <th>nerReview</th>\n",
       "      <th>lemmaReview</th>\n",
       "      <th>hyperReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149538/</td>\n",
       "      <td>1999-11-25</td>\n",
       "      <td>Dumbest, Most Cornball Film Ever Made</td>\n",
       "      <td>I still remember my initial outrage that this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>i remember initial outrage piece sentimental s...</td>\n",
       "      <td>anger part feed product  remark inability  be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw4247059/</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>Rubbish</td>\n",
       "      <td>The fight scenes are pathetic and the acting i...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td></td>\n",
       "      <td>the fight scene pathetic act laughable rubbish</td>\n",
       "      <td>military_action area activity waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw0149534/</td>\n",
       "      <td>1998-08-19</td>\n",
       "      <td>overrated piece of cheese</td>\n",
       "      <td>grubby late-night fare achieved way too much s...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>Apollo Creed Aki Kaurismaki Rocky VI</td>\n",
       "      <td>grubby late-night fare achieve way succes prim...</td>\n",
       "      <td>agenda succeed property happening message musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw2406266/</td>\n",
       "      <td>2011-03-30</td>\n",
       "      <td>I can't believe the script was made into a mov...</td>\n",
       "      <td>I was told by many that Rocky is a beautiful m...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>Rocky Stalone</td>\n",
       "      <td>i tell Rocky beautiful movie i watch i do the ...</td>\n",
       "      <td>express product   product move rate imaginary_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>http:/review/rw3451942/</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>Hate me if you want but I didn't like this film</td>\n",
       "      <td>I'm going to come out and say it. I didn't lik...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>Rocky Stallone Rocky Rocky God Burgess Meredit...</td>\n",
       "      <td>i be go come say i do be like film i know go h...</td>\n",
       "      <td>travel express  desire product   emotion fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie                ReviewUrl  ReviewDate  \\\n",
       "0  Rocky  http:/review/rw0149538/  1999-11-25   \n",
       "1  Rocky  http:/review/rw4247059/  2018-07-21   \n",
       "2  Rocky  http:/review/rw0149534/  1998-08-19   \n",
       "3  Rocky  http:/review/rw2406266/  2011-03-30   \n",
       "4  Rocky  http:/review/rw3451942/  2016-04-15   \n",
       "\n",
       "                                         ReviewTitle  \\\n",
       "0              Dumbest, Most Cornball Film Ever Made   \n",
       "1                                            Rubbish   \n",
       "2                          overrated piece of cheese   \n",
       "3  I can't believe the script was made into a mov...   \n",
       "4    Hate me if you want but I didn't like this film   \n",
       "\n",
       "                                              Review Rating Language  \\\n",
       "0  I still remember my initial outrage that this ...      1  English   \n",
       "1  The fight scenes are pathetic and the acting i...      1  English   \n",
       "2  grubby late-night fare achieved way too much s...      2  English   \n",
       "3  I was told by many that Rocky is a beautiful m...      3  English   \n",
       "4  I'm going to come out and say it. I didn't lik...      3  English   \n",
       "\n",
       "                                           nerReview  \\\n",
       "0                                          Hollywood   \n",
       "1                                                      \n",
       "2               Apollo Creed Aki Kaurismaki Rocky VI   \n",
       "3                                      Rocky Stalone   \n",
       "4  Rocky Stallone Rocky Rocky God Burgess Meredit...   \n",
       "\n",
       "                                         lemmaReview  \\\n",
       "0  i remember initial outrage piece sentimental s...   \n",
       "1     the fight scene pathetic act laughable rubbish   \n",
       "2  grubby late-night fare achieve way succes prim...   \n",
       "3  i tell Rocky beautiful movie i watch i do the ...   \n",
       "4  i be go come say i do be like film i know go h...   \n",
       "\n",
       "                                         hyperReview  \n",
       "0   anger part feed product  remark inability  be...  \n",
       "1                military_action area activity waste  \n",
       "2  agenda succeed property happening message musi...  \n",
       "3  express product   product move rate imaginary_...  \n",
       "4   travel express  desire product   emotion fact...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReviewDetails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReviewDetails.to_pickle(\"./dfReviewDetailsPlus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(hypernymList))\n",
    "print(len(lemmaList))\n",
    "print(len(nerList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(max_df=1, min_df=0, stop_words='english', use_idf=True, ngram_range=(1,3))\n",
    "countVectorizer = CountVectorizer(analyzer='word', min_df=9, stop_words='english', lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 29087)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMatrix = tfidfVectorizer.fit_transform(dfReviewDetails.Review)\n",
    "tfidfMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 271)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvReview = countVectorizer.fit_transform(dfReviewDetails.Review)\n",
    "cvReview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 29)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvNer = countVectorizer.fit_transform(dfReviewDetails.nerReview)\n",
    "cvNer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 273)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvLemma = countVectorizer.fit_transform(dfReviewDetails.lemmaReview)\n",
    "cvLemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 167)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvHyper = countVectorizer.fit_transform(dfReviewDetails.hyperReview)\n",
    "cvHyper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparseness:  13.40959409594096 %\n"
     ]
    }
   ],
   "source": [
    "#sparceness\n",
    "cvDense = cvReview.todense()\n",
    "print(\"Sparseness: \", ((cvDense > 0).sum()/cvDense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA Model GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "parmGrid = {'n_topics': [3, 5, 7, 9], \n",
    "            'learning_method': ['online'], \n",
    "            'random_state': [2019], \n",
    "            'learning_decay': [0.5, 0.7, 0.9], \n",
    "            'max_iter': [5, 10]}\n",
    "\n",
    "ldaGrid = GridSearchCV(lda, param_grid=parmGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTopic(matrixIn):\n",
    "    clf = ldaGrid.fit(matrixIn)\n",
    "    print(clf.best_estimator_)\n",
    "    print(clf.best_params_)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.9,\n",
      "             learning_method='online', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=3, perp_tol=0.1,\n",
      "             random_state=2019, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "{'learning_decay': 0.9, 'learning_method': 'online', 'max_iter': 5, 'n_topics': 3, 'random_state': 2019}\n"
     ]
    }
   ],
   "source": [
    "ldaClf = modelTopic(cvHyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-44264.03007073572\n"
     ]
    }
   ],
   "source": [
    "#ldaReview = ldaClf.best_estimator_.fit_transform(cvReview)\n",
    "ldaHyper = ldaClf.best_estimator_.fit_transform(cvReview)\n",
    "print(ldaClf.score(cvReview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Topic-term distributions and document-term matrix have different number of columns, 271 != 167.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-553f39235652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#panel = pyLDAvis.sklearn.prepare(ldaClf.best_estimator_, cvReview, countVectorizer, mds='tsne')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpanel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldaClf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcvHyper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tsne'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpanel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         ('Topic-term distributions and document-term matrix have different number of columns, {} != {}.'\n\u001b[1;32m---> 49\u001b[1;33m          .format(topic_term_dists.shape[1], len(vocab)))\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# column dimensions of document-term matrix and topic-term distributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Topic-term distributions and document-term matrix have different number of columns, 271 != 167."
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "#panel = pyLDAvis.sklearn.prepare(ldaClf.best_estimator_, cvReview, countVectorizer, mds='tsne')\n",
    "panel = pyLDAvis.sklearn.prepare(ldaClf.best_estimator_, cvHyper, countVectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA for Full Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_topics': [3, 5, 7, 9], 'learning_method': ['online'], 'random_state': [2019], 'learning_decay': [0.5, 0.7, 0.9], 'max_iter': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaGrid.fit(cvReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.9,\n",
      "             learning_method='online', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=3, perp_tol=0.1,\n",
      "             random_state=2019, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "{'learning_decay': 0.9, 'learning_method': 'online', 'max_iter': 5, 'n_topics': 3, 'random_state': 2019}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Estimator:\", ldaGrid.best_estimator_)\n",
    "print(ldaGrid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Review Model Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -44264.03007073572\n"
     ]
    }
   ],
   "source": [
    "ldaTest = ldaGrid.best_estimator_.fit_transform(cvReview)\n",
    "print(\"Log Likelihood:\", ldaGrid.best_estimator_.score(cvReview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original trained model\n",
    "#\n",
    "#lda = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', random_state=2019, batch_size=120, \n",
    "#                               evaluate_every=-1, n_jobs=-1)\n",
    "#\n",
    "#ldaFit = lda.fit_transform(cvMatrix)\n",
    "ldaBest = LatentDirichletAllocation(n_topics=3, max_iter=5, learning_method='online', learning_decay=0.9, \n",
    "                                    random_state=2019, evaluate_every=-1, n_jobs=-1)\n",
    "ldaBestFit = ldaBest.fit_transform(cvReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -44257.87710120041\n",
      "Perplexity: 187.40711341898282\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Likelihood:\", ldaBest.score(cvReview))\n",
    "print(\"Perplexity:\", ldaBest.perplexity(cvReview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA Model Scoring\n",
    "\n",
    "Original Model\n",
    "\n",
    "print(\"Log Likelihood:\", lda.score(cvMatrix))\n",
    "\n",
    "print(\"Perplexity:\", lda.perplexity(cvMatrix))\n",
    "\n",
    "Log Likelihood: -65854.02334362216\n",
    "\n",
    "Perplexity: 456.28047756163363"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pyLDAvis Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Term frequencies and vocabulary are of different sizes, 271 != 167.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-052a2adf677e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#panel = pyLDAvis.sklearn.prepare(lda, cvMatrix, countVectorizer, mds='tsne')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpanel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldaBest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcvReview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tsne'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpanel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mterm_freqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         ('Term frequencies and vocabulary are of different sizes, {} != {}.'\n\u001b[1;32m---> 45\u001b[1;33m          .format(term_freqs.shape[0], len(vocab)))\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Term frequencies and vocabulary are of different sizes, 271 != 167."
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "#panel = pyLDAvis.sklearn.prepare(lda, cvMatrix, countVectorizer, mds='tsne')\n",
    "panel = pyLDAvis.sklearn.prepare(ldaBest, cvReview, countVectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA for Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
