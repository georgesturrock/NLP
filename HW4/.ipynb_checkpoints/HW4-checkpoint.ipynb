{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Version: 3.4\n",
      "Pattern Version: 3.6\n",
      "Spacy Version: 2.0.16\n",
      "Pandas Version: 0.24.1\n",
      "PIL Image Version: 5.4.1\n"
     ]
    }
   ],
   "source": [
    "import nltk; print(\"NLTK Version:\", nltk.__version__)\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import pattern; print(\"Pattern Version:\", pattern.__version__)\n",
    "from pattern.en import tag\n",
    "\n",
    "###https://spacy.io/usage/models\n",
    "###https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "import spacy; print(\"Spacy Version:\", spacy.__version__)\n",
    "#spacy.prefer_gpu()\n",
    "\n",
    "import pandas as pd; print(\"Pandas Version:\", pd.__version__)\n",
    "\n",
    "from PIL import Image; print(\"PIL Image Version:\", Image.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part of Speach Tagging Function\n",
    "The \"tagPOS\" function implements NLTK, Pattern and Spacy part of speach (POS) taggers.  The function inputs are the text to be tagged and the POS tagger to utilize.  The return value is dependent upon the POS tagger utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagPOS(text, tagger):\n",
    "    if tagger != \"nltk\" and \"pattern\" and \"spacy\":\n",
    "        tagger = \"nltk\"\n",
    "        \n",
    "    if tagger=='nltk':\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tagTokens = nltk.pos_tag(tokens)\n",
    "    elif tagger=='pattern':\n",
    "        tagTokens = tag(text)\n",
    "    elif tagger == 'spacy':\n",
    "        nlp = spacy.load('en')\n",
    "        tagTokens = nlp(longSent)\n",
    "    return tagTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 4 - Question 1 - Part A\n",
    "This question asks for a sentence longer than ten words to be part of speach tagged by one of the taggers implemented in the \"tagPOS\" function.  The sentence used is one of the sentences from the Introduction of my capstone project.  This sentence is stored in the \"longSent\" string variable shown below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "longSent = \"Throughout history, astronomy has influenced religion, guided explorers, defined food production schedules and  fueled  philosophical  questions  surrounding  our  very  existence  and  role  in  the universe.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK tagger is used to tag \"longSent\".  The output is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK_POS_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Throughout</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>history</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>influenced</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>religion</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guided</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>explorers</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>defined</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>food</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>production</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>schedules</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fueled</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>philosophical</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>questions</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>surrounding</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>very</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>existence</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>role</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>universe</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Token NLTK_POS_Tag\n",
       "0      Throughout           IN\n",
       "1         history           NN\n",
       "2       astronomy           NN\n",
       "3             has          VBZ\n",
       "4      influenced          VBN\n",
       "5        religion           NN\n",
       "6          guided          VBD\n",
       "7       explorers          NNS\n",
       "8         defined          VBD\n",
       "9            food           NN\n",
       "10     production           NN\n",
       "11      schedules          NNS\n",
       "12            and           CC\n",
       "13         fueled          VBD\n",
       "14  philosophical           JJ\n",
       "15      questions          NNS\n",
       "16    surrounding          VBG\n",
       "17            our         PRP$\n",
       "18           very           NN\n",
       "19      existence           NN\n",
       "20            and           CC\n",
       "21           role           NN\n",
       "22             in           IN\n",
       "23            the           DT\n",
       "24       universe           NN\n",
       "25              .            ."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Token', 'NLTK_POS_Tag'])\n",
    "\n",
    "ltt = tagPOS(longSent, 'nltk')\n",
    "\n",
    "for l in ltt:\n",
    "    if l[0] != \",\" and \".\":\n",
    "        df = df.append({'Token':l[0], 'NLTK_POS_Tag':l[1]}, ignore_index=True)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 4 - Question 1 - Part B\n",
    "This question is the second part of homework 4, question 1.  The goal of this part of the question is to tag parts of speach in a sentence shorter than ten words and is not classified 100% correctly.  The sentence is shown below in the \"shortSent\" variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent = \"Run!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagramming the short sentence illustrates the noun and verb constructs of an imperative sentence.  The understood you is not physically part of the sentence.  However, it is the noun subject of the sentence and \"Run\" is the verb.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=176x92 at 0x264FE618FD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image.open('uYouDiagram.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the short sentence tagging using NLTK is shown below.  NLTK appears to mis-tag the verb \"Run\" as a noun.  This could be a bit of a trick question.  The sentence below uses an \"understood you\".  In English, commands such as \"Run!\" carry an implied subject of \"You\".  The understood you is a personal pronoun.  The verb in this sentence is \"Run\".  There could be several reasons why NLTK mis-tagged \"Run\" in this sentence.  First, NLTK is likely not programmed to detect an understood you.  Second, \"Run\" is captialized.  This could have been lead NLTK to conclude the word is actually a named entity noun.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK_POS_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Token NLTK_POS_Tag\n",
       "0   Run           NN\n",
       "1     !            ."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(columns=['Token', 'NLTK_POS_Tag'])\n",
    "\n",
    "ltts = tagPOS(shortSent, \"nltk\")\n",
    "\n",
    "for l in ltts:\n",
    "    df2 = df2.append({'Token':l[0], 'NLTK_POS_Tag':l[1]}, ignore_index=True)\n",
    "    \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 4 - Question 2\n",
    "Question 2 from homework 4 is a two part question which requests the sentences from homework 4 question 1 be run through different POS taggers.   We will use Pattern and Spacy POS taggers.  The results of these POS taggers will be compared to the output of the NLTK POS tagger.  Examination of the dataframe shown below shown all three POS taggers tagged the long sentence exactly the same.  This is a bit surprising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK_POS_Tag</th>\n",
       "      <th>Pattern_POS_Tag</th>\n",
       "      <th>Spacy_POS_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Throughout</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>history</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>influenced</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>religion</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guided</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>explorers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>defined</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>food</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>production</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>schedules</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fueled</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>philosophical</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>questions</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>surrounding</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>very</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>existence</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>role</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>universe</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Token NLTK_POS_Tag Pattern_POS_Tag Spacy_POS_Tag\n",
       "0      Throughout           IN              IN            IN\n",
       "1         history           NN              NN            NN\n",
       "2       astronomy           NN              NN            NN\n",
       "3             has          VBZ             VBZ           VBZ\n",
       "4      influenced          VBN             VBN           VBN\n",
       "5        religion           NN              NN            NN\n",
       "6          guided          VBD             VBD           VBD\n",
       "7       explorers          NNS             NNS           NNS\n",
       "8         defined          VBD             VBD           VBD\n",
       "9            food           NN              NN            NN\n",
       "10     production           NN              NN            NN\n",
       "11      schedules          NNS             NNS           NNS\n",
       "12            and           CC              CC            CC\n",
       "13         fueled          VBD             VBD           VBD\n",
       "14  philosophical           JJ              JJ            JJ\n",
       "15      questions          NNS             NNS           NNS\n",
       "16    surrounding          VBG             VBG           VBG\n",
       "17            our         PRP$            PRP$          PRP$\n",
       "18           very           NN              NN            NN\n",
       "19      existence           NN              NN            NN\n",
       "20            and           CC              CC            CC\n",
       "21           role           NN              NN            NN\n",
       "22             in           IN              IN            IN\n",
       "23            the           DT              DT            DT\n",
       "24       universe           NN              NN            NN\n",
       "25              .            .               .             ."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltt2 = tagPOS(longSent, 'pattern')\n",
    "\n",
    "df3 = pd.DataFrame(columns=['Token', 'Pattern_POS_Tag'])\n",
    "\n",
    "for l in ltt2:\n",
    "    if l[0] != ',':\n",
    "        df3 = df3.append({'Token':l[0], 'Pattern_POS_Tag':l[1]}, ignore_index=True)\n",
    "        \n",
    "df['Pattern_POS_Tag'] = df3['Pattern_POS_Tag']\n",
    "\n",
    "ltt3 = tagPOS(longSent, \"spacy\")\n",
    "\n",
    "df4 = pd.DataFrame(columns=['Token', 'Spacy_POS_Tag'])\n",
    "\n",
    "for l in ltt3:\n",
    "    if l[0] != ',':\n",
    "        df4 = df4.append({'Token':l[0], 'Spacy_POS_Tag':l[1]}, ignore_index=True) \n",
    "        \n",
    "df['Spacy_POS_Tag'] = df4['Spacy_POS_Tag']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print([(l.text, l.tag_) for l in ltt3a if l.text != ' ' and ','])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Run', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagPOS(shortSent, \"pattern\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Run', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagPOS(shortSent, \"spacy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ltt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 4 - Question 3 - Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
